{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e002360",
   "metadata": {},
   "source": [
    "**Problem statement:-**\n",
    "The aim of the project is to predict fraudulent credit card transactions using machine learning models. This is crucial from the bank’s as well as customer’s perspective. The banks cannot afford to lose their customers’ money to fraudsters. Every fraud is a loss to the bank as the bank is responsible for the fraud transactions.\n",
    "\n",
    "The dataset contains transactions made over a period of two days in September 2013 by European credit cardholders. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. We need to take care of the data imbalance while building the model and come up with the best model by trying various algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693ad78",
   "metadata": {},
   "source": [
    "The steps are broadly divided into below steps. \n",
    "\n",
    "The sub steps are also listed while we approach each of the steps.\n",
    "\n",
    "Reading, understanding and visualising the data\n",
    "Preparing the data for modelling\n",
    "Building the model\n",
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26555c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ctgan import CTGAN \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "\n",
    "# Importing scikit logistic regression module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Impoting metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing libraries for cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe918b5",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f0e60",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58fac4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\irfan\\Downloads\\archive\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d21e0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6a8c4d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9ff80",
   "metadata": {},
   "source": [
    "Handling missing values\n",
    "Handling missing values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86b95b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        null\n",
       "Time     0.0\n",
       "V16      0.0\n",
       "Amount   0.0\n",
       "V28      0.0\n",
       "V27      0.0\n",
       "V26      0.0\n",
       "V25      0.0\n",
       "V24      0.0\n",
       "V23      0.0\n",
       "V22      0.0\n",
       "V21      0.0\n",
       "V20      0.0\n",
       "V19      0.0\n",
       "V18      0.0\n",
       "V17      0.0\n",
       "V15      0.0\n",
       "V1       0.0\n",
       "V14      0.0\n",
       "V13      0.0\n",
       "V12      0.0\n",
       "V11      0.0\n",
       "V10      0.0\n",
       "V9       0.0\n",
       "V8       0.0\n",
       "V7       0.0\n",
       "V6       0.0\n",
       "V5       0.0\n",
       "V4       0.0\n",
       "V3       0.0\n",
       "V2       0.0\n",
       "Class    0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cde3b",
   "metadata": {},
   "source": [
    "We can see that there is no missing values in any of the columns. Hence, there is no problem with null values in the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b519d",
   "metadata": {},
   "source": [
    "Checking the distribution of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee236980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['Class'].value_counts()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "334a72cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_share = round((classes[0]/df['Class'].count()*100),2)\n",
    "normal_share\n",
    "\n",
    "\n",
    "fraud_share = round((classes[1]/df['Class'].count()*100),2)\n",
    "fraud_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aaf1be7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot for the number of fraudulent vs non-fraudulent transcations\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Number of fraudulent vs non-fraudulent transcations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9cb24",
   "metadata": {},
   "source": [
    "Now checking Time value in case of Fraud and Normal Transaction compared according to Number of transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7be09983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, (axis_1, axis_2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "bins = 50\n",
    "\n",
    "axis_1.hist(df.Time[df.Class == 1], bins = bins)\n",
    "axis_1.set_title('Fraud')\n",
    "\n",
    "axis_2.hist(df.Time[df.Class == 0], bins = bins)\n",
    "axis_2.set_title('Normal (Non-Fraud)')\n",
    "\n",
    "plt.xlabel('Time (in Seconds)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b433f",
   "metadata": {},
   "source": [
    "Now checking Amount in case of Fraud and Normal Transaction compared according to Number of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55e0d2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+wAAAGHCAYAAAAqddg4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEQklEQVR4nO3deVyVZf7/8fcBATcgEQGPIlCZSygqlrklZm4jpllpWaRmzaipkZZKNiM6jahNtpk2loktZtM3tc003EhzyY3cLUsTFXIjQDRQuH9/NJ5fR1A5eg7nRl7Px+M8Hpzrurjvz328OjNvrnuxGIZhCAAAAAAAmIqHuwsAAAAAAADFEdgBAAAAADAhAjsAAAAAACZEYAcAAAAAwIQI7AAAAAAAmBCBHQAAAAAAEyKwAwAAAABgQgR2AAAAAABMiMAOAAAAAIAJEdgBAKgAkpOTZbFYSnw988wz7i5PkjRw4ECFh4e7uwwAAEyjkrsLAAAAZWfu3Llq2LChXZvVanVTNQAA4HII7AAAVCCRkZFq2bLlFcedO3dOFotFlSrxfxUAAHAXTokHAKCCW716tSwWi9577z2NHj1aderUkY+Pj/bv36/jx49r2LBhaty4sapXr66goCDdddddWrNmTYnbWL16tV37wYMHZbFYlJycbNeenJysBg0ayMfHR40aNdK7777r4qMEAKD84c/mAABUIIWFhTp//nyJfQkJCWrdurXefPNNeXh4KCgoSMePH5ckTZgwQSEhITp9+rQWLVqkmJgYrVixQjExMQ7XkJycrEGDBqlXr1566aWXlJ2drcTEROXn58vDg7UEAAAuILADAFCB3HHHHcXaUlJSJEk33XSTPv74Y7u+gIAAzZw50/a+sLBQXbt21cGDB/Xaa685HNiLioo0fvx4tWjRQosWLZLFYpEktWvXTvXr1+d6egAA/oTADgBABfLuu++qUaNGdm2nT5+WJN13330l/s6bb76p2bNna/fu3crPz7e1X3zzutLYt2+fjh49qlGjRtnCuiSFhYWpTZs2OnjwoMPbBADgesV5ZwAAVCCNGjVSy5Yt7V4X1K5du9j46dOna+jQoWrVqpU++eQTbdiwQZs2bVK3bt109uxZh/d/8uRJSVJISEixvpLaAACoyFhhBwAAkmS34n3B+++/r5iYGM2aNcuuPTc31+595cqVJcluBV6STpw4Yfe+Zs2akqTMzMxi+yqpDQCAiowVdgAAcEkWi0U+Pj52bdu3b9f69evt2sLDw219f/bZZ5/ZvW/QoIFq166tDz/8UIZh2Np/+eUXrVu3zomVAwBQ/rHCDgAALik2Nlb//Oc/NWHCBHXo0EH79u3TpEmTFBERYXe3+ZCQEN19991KSkpSjRo1FBYWphUrVmjhwoV22/Pw8NA///lPPf7447r33nv1xBNP6LffflNiYiKnxAMAcBECOwAAuKTx48frzJkzmjNnjqZNm6bGjRvrzTff1KJFi4o9c/29997TiBEjNHbsWBUWFqpnz5768MMP7a6Tl6TBgwdLkqZOnao+ffooPDxczz33nFJTU4ttEwCAisxi/Pl8NAAAAAAAYApcww4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATqtDPYS8qKtLRo0fl6+sri8Xi7nIAAAAAANc5wzCUm5srq9UqD4/Lr6FX6MB+9OhRhYaGursMAAAAAEAFk56errp16152TIUO7L6+vpL++KD8/PzcXA0AAAAA4HqXk5Oj0NBQWx69nAod2C+cBu/n50dgBwAAAACUmdJcls1N5wAAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjs5Uj4uC8VPu5Ld5cBAAAAACgDBHYAAAAAAEyIwA4AAAAAgAm5JbDPmjVLTZs2tT1OrXXr1vrqq69s/YZhKDExUVarVVWqVFFMTIx27dplt438/HyNGDFCgYGBqlatmu655x4dPny4rA8FAAAAAACXcEtgr1u3rqZMmaLNmzdr8+bNuuuuu9SrVy9bKJ82bZqmT5+uGTNmaNOmTQoJCVHnzp2Vm5tr20Z8fLwWLVqkBQsWaO3atTp9+rRiY2NVWFjojkMCAAAAAMCpLIZhGO4uQpICAgL04osv6rHHHpPValV8fLzGjh0r6Y/V9ODgYE2dOlV/+9vflJ2drVq1aum9995Tv379JElHjx5VaGiolixZoq5du5Zqnzk5OfL391d2drb8/PxcdmzOcuGGcwen9HBzJQAAAACAq+FIDnX7NeyFhYVasGCB8vLy1Lp1ax04cECZmZnq0qWLbYyPj486dOigdevWSZK2bNmic+fO2Y2xWq2KjIy0jSlJfn6+cnJy7F4AAAAAAJiR2wL7jh07VL16dfn4+GjIkCFatGiRGjdurMzMTElScHCw3fjg4GBbX2Zmpry9vVWjRo1LjilJUlKS/P39ba/Q0FAnHxUAAAAAAM7htsDeoEEDpaWlacOGDRo6dKgGDBig3bt32/otFovdeMMwirVd7EpjEhISlJ2dbXulp6df20EAAAAAAOAibgvs3t7euvnmm9WyZUslJSUpKipKr776qkJCQiSp2Er5sWPHbKvuISEhKigoUFZW1iXHlMTHx8d2Z/oLLwAAAAAAzMjt17BfYBiG8vPzFRERoZCQEKWkpNj6CgoKlJqaqjZt2kiSoqOj5eXlZTcmIyNDO3futI0BAAAAAKA8q+SOnT733HPq3r27QkNDlZubqwULFmj16tVaunSpLBaL4uPjNXnyZNWvX1/169fX5MmTVbVqVfXv31+S5O/vr8GDB2v06NGqWbOmAgIC9Mwzz6hJkya6++673XFIAAAAAAA4lVsC+6+//qq4uDhlZGTI399fTZs21dKlS9W5c2dJ0pgxY3T27FkNGzZMWVlZatWqlb7++mv5+vratvHyyy+rUqVK6tu3r86ePatOnTopOTlZnp6e7jgkAAAAAACcyjTPYXcHnsMOAAAAAChL5eo57AAAAAAAoDgCOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEzILYE9KSlJt912m3x9fRUUFKTevXtr3759dmMMw1BiYqKsVquqVKmimJgY7dq1y25Mfn6+RowYocDAQFWrVk333HOPDh8+XJaHAgAAAACAS7glsKempurJJ5/Uhg0blJKSovPnz6tLly7Ky8uzjZk2bZqmT5+uGTNmaNOmTQoJCVHnzp2Vm5trGxMfH69FixZpwYIFWrt2rU6fPq3Y2FgVFha647AAAAAAAHAai2EYhruLOH78uIKCgpSamqo777xThmHIarUqPj5eY8eOlfTHanpwcLCmTp2qv/3tb8rOzlatWrX03nvvqV+/fpKko0ePKjQ0VEuWLFHXrl2vuN+cnBz5+/srOztbfn5+Lj1GZwgf96Uk6eCUHm6uBAAAAABwNRzJoaa4hj07O1uSFBAQIEk6cOCAMjMz1aVLF9sYHx8fdejQQevWrZMkbdmyRefOnbMbY7VaFRkZaRtzsfz8fOXk5Ni9AAAAAAAwI7cHdsMwNGrUKLVr106RkZGSpMzMTElScHCw3djg4GBbX2Zmpry9vVWjRo1LjrlYUlKS/P39ba/Q0FBnHw4AAAAAAE7h9sA+fPhwbd++XR9++GGxPovFYvfeMIxibRe73JiEhARlZ2fbXunp6VdfOAAAAAAALuTWwD5ixAh99tlnWrVqlerWrWtrDwkJkaRiK+XHjh2zrbqHhISooKBAWVlZlxxzMR8fH/n5+dm9AAAAAAAwI7cEdsMwNHz4cC1cuFArV65URESEXX9ERIRCQkKUkpJiaysoKFBqaqratGkjSYqOjpaXl5fdmIyMDO3cudM2BgAAAACA8qqSO3b65JNPav78+fr000/l6+trW0n39/dXlSpVZLFYFB8fr8mTJ6t+/fqqX7++Jk+erKpVq6p///62sYMHD9bo0aNVs2ZNBQQE6JlnnlGTJk109913u+OwAAAAAABwGrcE9lmzZkmSYmJi7Nrnzp2rgQMHSpLGjBmjs2fPatiwYcrKylKrVq309ddfy9fX1zb+5ZdfVqVKldS3b1+dPXtWnTp1UnJysjw9PcvqUAAAAAAAcAlTPIfdXXgOOwAAAACgLJW757ADAAAAAAB7BHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATcltg/+abb9SzZ09ZrVZZLBYtXrzYrt8wDCUmJspqtapKlSqKiYnRrl277Mbk5+drxIgRCgwMVLVq1XTPPffo8OHDZXgUAAAAAAC4htsCe15enqKiojRjxowS+6dNm6bp06drxowZ2rRpk0JCQtS5c2fl5ubaxsTHx2vRokVasGCB1q5dq9OnTys2NlaFhYVldRgAAAAAALhEJXftuHv37urevXuJfYZh6JVXXtH48ePVp08fSdK8efMUHBys+fPn629/+5uys7M1Z84cvffee7r77rslSe+//75CQ0O1fPlyde3atcyOBQAAAAAAZzPlNewHDhxQZmamunTpYmvz8fFRhw4dtG7dOknSli1bdO7cObsxVqtVkZGRtjEXy8/PV05Ojt0LAAAAAAAzMmVgz8zMlCQFBwfbtQcHB9v6MjMz5e3trRo1alxyzMWSkpLk7+9ve4WGhrqgegAAAAAArp0pA/sFFovF7r1hGMXaLna5MQkJCcrOzra90tPTnVYrAAAAAADOZMrAHhISIknFVsqPHTtmW3UPCQlRQUGBsrKyLjnmYj4+PvLz87N7AQAAAABgRqYM7BEREQoJCVFKSoqtraCgQKmpqWrTpo0kKTo6Wl5eXnZjMjIytHPnTtsYAAAAAADKK7fdJf706dPav3+/7f2BAweUlpamgIAA1atXT/Hx8Zo8ebLq16+v+vXra/Lkyapatar69+8vSfL399fgwYM1evRo1axZUwEBAXrmmWfUpEkT213jAQAAAAAor9wW2Ddv3qyOHTva3o8aNUqSNGDAACUnJ2vMmDE6e/ashg0bpqysLLVq1Upff/21fH19bb/z8ssvq1KlSurbt6/Onj2rTp06KTk5WZ6enmV+PAAAAAAAOJPFMAzD3UW4S05Ojvz9/ZWdnV0urmcPH/elJOnglB5urgQAAAAAcDUcyaGmvIYdAAAAAICKjsAOAAAAAIAJEdgBAAAAADAhAns5FD7uS9v17AAAAACA6xOBHQAAAAAAEyKwAwAAAABgQgR2AAAAAABMiMAOAAAAAIAJEdgBAAAAADAhAjsAAAAAACZEYAcAAAAAwIQI7AAAAAAAmBCBHQAAAAAAEyKwAwAAAABgQgR2AAAAAABMiMAOAAAAAIAJEdgBAAAAADAhAjsAAAAAACZEYAcAAAAAwIQI7AAAAAAAmBCBHQAAAAAAEyKwAwAAAABgQgR2AAAAAABMiMAOAAAAAIAJEdgBAAAAADAhAjsAAAAAACZUyd0F4OqFj/vS9vPBKT3cWAkAAAAAwNlYYb/OhI/70i7IAwAAAADKJ1bYrxOEdAAAAAC4vrDCDgAAAACACRHYAQAAAAAwoesisM+cOVMRERGqXLmyoqOjtWbNGneXVO5w7TsAAAAAmEu5v4b9o48+Unx8vGbOnKm2bdvqP//5j7p3767du3erXr167i7PbUoK39xJHgAAAADKD4thGIa7i7gWrVq1UosWLTRr1ixbW6NGjdS7d28lJSVd9ndzcnLk7++v7Oxs+fn5ubrUa+aKFfALId4VAf/CNvlDAQAAAAD8wZEcWq5X2AsKCrRlyxaNGzfOrr1Lly5at25dsfH5+fnKz8+3vc/Ozpb0xwdWHhTln3H6Nus9/fEl+y58LpETll1yzM6JXa845s+f74VxF36vJI6MudI4AAAAADCTC/moNGvn5TqwnzhxQoWFhQoODrZrDw4OVmZmZrHxSUlJmjhxYrH20NBQl9VYnvm/4roxztq2I+MAAAAAwCxyc3Pl7+9/2THlOrBfYLFY7N4bhlGsTZISEhI0atQo2/uioiKdOnVKNWvWLHG8meTk5Cg0NFTp6enl4vR9XN+YjzAb5iTMhPkIs2FOwkyYj3/k1dzcXFmt1iuOLdeBPTAwUJ6ensVW048dO1Zs1V2SfHx85OPjY9d2ww03uLJEp/Pz86uwExvmw3yE2TAnYSbMR5gNcxJmUtHn45VW1i8o14918/b2VnR0tFJSUuzaU1JS1KZNGzdVBQAAAADAtSvXK+ySNGrUKMXFxally5Zq3bq1Zs+erUOHDmnIkCHuLg0AAAAAgKtW7gN7v379dPLkSU2aNEkZGRmKjIzUkiVLFBYW5u7SnMrHx0cTJkwodko/4A7MR5gNcxJmwnyE2TAnYSbMR8eU++ewAwAAAABwPSrX17ADAAAAAHC9IrADAAAAAGBCBHYAQIWUnJwsi8WiypUr65dffinWHxMTo8jISDdU5hwDBw5UeHh4qcd36tTJ7oatq1evlsVikcVi0fr160vcfvXq1Z1R6lW5UNvFr8DAQLfVdLELn+Hq1attbXFxcerdu7fbagIAlC/l/qZzAABci/z8fD3//PN677333F2K23z66af69ttv9e6775bYP2bMGK1Zs6aMq7qy+++/X6NHj7Zr8/LyclM1pZOYmKiGDRtq5cqVuuuuu9xdDgDA5FhhBwBUaN26ddP8+fP1/fffu3Q/Z8+eden2r8XkyZN17733qk6dOsX6unXrprVr1+rzzz93Q2WXFxwcrDvuuMPuFR0dfcnxZvg3uOmmm9StWzdNmTLF3aUAAMoBAjsAoEIbM2aMatasqbFjx15x7O+//66EhARFRETI29tbderU0ZNPPqnffvvNblx4eLhiY2O1cOFCNW/eXJUrV9bEiRNtp0jPnz9fY8eOVe3atVW9enX17NlTv/76q3Jzc/XXv/5VgYGBCgwM1KBBg3T69Gm7bb/xxhu68847FRQUpGrVqqlJkyaaNm2azp07d1XHv23bNn333XeKi4srsX/gwIFq3LixEhISVFhYeNltFRUVadq0aWrYsKF8fHwUFBSkRx99VIcPH7Ybd+Fyg02bNql9+/aqWrWqbrzxRk2ZMkVFRUVXdRwXu9S/gVT6zzA8PFwDBw4stu2YmBjFxMTYte3du1fdunVT1apVFRgYqCFDhig3N7fE2uLi4rR8+XL99NNPTjlWAMD1i1PiAQAVmq+vr55//nk99dRTlz1N2TAM9e7dWytWrFBCQoLat2+v7du3a8KECVq/fr3Wr19v90zZrVu3as+ePXr++ecVERGhatWqKS8vT5L03HPPqWPHjkpOTtbBgwf1zDPP6KGHHlKlSpUUFRWlDz/8UNu2bdNzzz0nX19fvfbaa7bt/vTTT+rfv7/tjwbff/+9/vWvf2nv3r165513HD7+L774Qp6enrrzzjtL7Pf09FRSUpJ69eqlefPm6bHHHrvktoYOHarZs2dr+PDhio2N1cGDB/X3v/9dq1ev1tatW+2uL8/MzNTDDz+s0aNHa8KECVq0aJESEhJktVr16KOPlqp2wzB0/vz5YvVaLBZJJf8bSM7/DH/99Vd16NBBXl5emjlzpoKDg/XBBx9o+PDhJY6PiYmRYRhasmSJRowY4fD+AAAViAEAQAU0d+5cQ5KxadMmIz8/37jxxhuNli1bGkVFRYZhGEaHDh2MW2+91TZ+6dKlhiRj2rRpdtv56KOPDEnG7NmzbW1hYWGGp6ensW/fPruxq1atMiQZPXv2tGuPj483JBkjR460a+/du7cREBBwyWMoLCw0zp07Z7z77ruGp6encerUKVvfgAEDjLCwsCt+Dt27dzcaNmxYrP1CrR9//LFhGIbRrl07o27dusbZs2dt269WrZpt/J49ewxJxrBhw+y2s3HjRkOS8dxzz9naOnToYEgyNm7caDe2cePGRteuXa9Ys2EYhqQSX2+99ZZhGJf+N7jY5T7DsLAwY8CAAcV+p0OHDkaHDh1s78eOHWtYLBYjLS3Nblznzp0NScaqVauKbaNOnTpGv379SnWsAICKi1PiAQAVnre3t1544QVt3rxZ//3vf0scs3LlSkkqdor0Aw88oGrVqmnFihV27U2bNtUtt9xS4rZiY2Pt3jdq1EiS1KNHj2Ltp06dsjstftu2bbrnnntUs2ZNeXp6ysvLS48++qgKCwv1ww8/XPlgL3L06FEFBQVdcdzUqVN1+PBhvfrqqyX2r1q1SlLxz+f2229Xo0aNin0+ISEhuv322+3amjZtanfH/sLCQp0/f972uvh0+b59+2rTpk12rz/fgf1S/wbO/gxXrVqlW2+9VVFRUXbt/fv3v+TvBAUF6ciRIw7vCwBQsRDYAQCQ9OCDD6pFixYaP358ideDnzx5UpUqVVKtWrXs2i0Wi0JCQnTy5Em79tq1a19yXwEBAXbvvb29L9v++++/S5IOHTqk9u3b68iRI3r11Ve1Zs0abdq0SW+88Yakq7up2tmzZ1W5cuUrjmvTpo169+6tKVOmKCsrq1j/heMv6bitVmuxz6dmzZrFxvn4+Ngdw0033SQvLy/ba9KkSXbja9WqpZYtW9q9/nzafUm1uOIzPHnypEJCQoq1l9R2QeXKlU1xEzwAgLld8zXshYWF2rFjh8LCwlSjRg1n1AQAQJmzWCyaOnWqOnfurNmzZxfrr1mzps6fP6/jx4/bhXbDMJSZmanbbrut2PacbfHixcrLy9PChQsVFhZma09LS7vqbQYGBurUqVOlGpuUlKTIyEhNnjy5WN+FAJ6RkaG6deva9R09evSqno/++eefKz8/3/bearU69Psl/Rs48hlWrlzZbv8XnDhxwu54atasqczMzGLjSmq74NSpUwoPD7/CEQAAKjqHV9jj4+M1Z84cSX+E9Q4dOqhFixYKDQ3V6tWrnV0fAABl5u6771bnzp01adKkYndn79SpkyTp/ffft2v/5JNPlJeXZ+t3pQsB9M83tzMMQ2+99dZVb7Nhw4b6+eefSz32scce0+uvv65Dhw7Z9V24Wd/Fn8+mTZu0Z8+eq/p8mjRpYrd67mhgL4kjn2F4eLi2b99u1/bDDz9o3759dm0dO3bUrl27ij0acP78+SXWcP78eaWnp6tx48ZXdQwAgIrD4cD+f//3f7ZrtD7//HMdOHBAe/fuVXx8vMaPH+/0AgEAKEtTp07V8ePHtWXLFrv2zp07q2vXrho7dqwmTpyo5cuXa/r06Ro0aJCaN29+yceiOVPnzp3l7e2thx56SF999ZUWLVqkrl27lniKemnFxMTo1KlTpb52OzExUZ6enrZr1i9o0KCB/vrXv+r111/X008/ra+//lqzZ89WbGysQkND9fTTT191jc7kyGcYFxen3bt3a9iwYVqxYoXeeecd3XPPPcUui4iPj1dgYKB69Oih5ORkffXVV3rkkUe0d+/eEmvYvn27zpw5o44dO7rkGAEA1w+HA/uJEyds12QtWbJEDzzwgG655RYNHjxYO3bscHqBAACUpebNm+uhhx4q1m6xWLR48WKNGjVKc+fO1V/+8hf9+9//VlxcnFauXGm3YusqDRs21CeffKKsrCz16dNHI0aMULNmzewe++aoXr16qXr16vr0009LNd5qtSo+Pr7EvlmzZmnKlClasmSJYmNjNX78eHXp0kXr1q0r8Zp1d3DkM+zfv7+mTZumZcuWKTY2VrNmzdKsWbOK3cguJCREqampaty4sYYOHapHHnlElStX1owZM0qsYfHixQoMDFSXLl1ccowAgOuHxTAMw5FfCAsL01tvvaVOnTopIiJCM2fOVGxsrHbt2qV27dpd01/5AQBA2RsxYoRWrFihXbt2ueTae/x/hYWFuvnmm9W/f3/961//cnc5AACTc3iFfdCgQerbt68iIyNlsVjUuXNnSdLGjRvVsGFDpxcIAABc6/nnn9eRI0f0ySefuLuU697777+v06dP69lnn3V3KQCAcsDhu8QnJiYqMjJS6enpeuCBB2ynAHp6emrcuHFOLxAAALhWcHCwPvjgA86SKwNFRUX64IMPdMMNN7i7FABAOeDwKfEAAAAAAMD1ruo57CtWrNCKFSt07NgxFRUV2fW98847TikMAAAAAICKzOHAPnHiRE2aNEktW7ZU7dq1uTkNAAAAAAAu4PAp8bVr19a0adPK5HmzrlZUVKSjR4/K19eXPzwAAAAAAFzOMAzl5ubKarXKw+Py94F3eIW9oKBAbdq0uerizOTo0aMKDQ11dxkAAAAAgAomPT1ddevWvewYh1fYx44dq+rVq+vvf//7NRVnBtnZ2brhhhuUnp4uPz8/d5cDAAAAALjO5eTkKDQ0VL/99pv8/f0vO9bhFfbff/9ds2fP1vLly9W0aVN5eXnZ9U+fPt3RTbrNhdPg/fz8COwAAAAAgDJTmsuyHQ7s27dvV7NmzSRJO3fudHiHAAAAAADgyhwO7KtWrXJFHQAAAAAA4E8uf0u6Kzh8+LCOHDnirFoAAAAAAMD/OLzCXlRUpBdeeEEvvfSSTp8+LUny9fXV6NGjNX78+Cvelh5XL3zcl2W6v4NTepTp/gAAAAAA/5/DgX38+PGaM2eOpkyZorZt28owDH377bdKTEzU77//rn/961+uqBMAAAAAgArF4cA+b948vf3227rnnntsbVFRUapTp46GDRtGYAcAAAAAwAkcPn/91KlTatiwYbH2hg0b6tSpU04pCgAAAACAis7hwB4VFaUZM2YUa58xY4aioqKcUhQAAAAAABWdw6fET5s2TT169NDy5cvVunVrWSwWrVu3Tunp6VqyZIkraryiSpUqKTIyUpLUsmVLvf32226pAwAAAAAAZ3E4sHfo0EE//PCD3njjDe3du1eGYahPnz4aNmyYrFarK2q8ohtuuEFpaWlu2TcAAAAAAK7gcGCXJKvVys3lAAAAAABwoVJdw759+3YVFRXZfr7cy1HffPONevbsKavVKovFosWLFxcbM3PmTEVERKhy5cqKjo7WmjVr7PpzcnIUHR2tdu3aKTU11eEaAAAAAAAwm1KtsDdr1kyZmZkKCgpSs2bNZLFYZBhGsXEWi0WFhYUOFZCXl6eoqCgNGjRI9913X7H+jz76SPHx8Zo5c6batm2r//znP+revbt2796tevXqSZIOHjwoq9WqnTt3qkePHtqxY4f8/PwcqgMAAAAAADMpVWA/cOCAatWqZfvZmbp3767u3btfsn/69OkaPHiwHn/8cUnSK6+8omXLlmnWrFlKSkqSJNu185GRkWrcuLF++OEHtWzZsti28vPzlZ+fb3ufk5PjzEMBAAAAAMBpSnVKfFhYmCwWiyTpl19+UZ06dRQWFmb3qlOnjn755RenFldQUKAtW7aoS5cudu1dunTRunXrJElZWVm2EH748GHt3r1bN954Y4nbS0pKkr+/v+0VGhrq1HoBAAAAAHAWh5/D3rFjR506dapYe3Z2tjp27OiUoi44ceKECgsLFRwcbNceHByszMxMSdKePXvUsmVLRUVFKTY2Vq+++qoCAgJK3F5CQoKys7Ntr/T0dKfWCwAAAACAszh8l3jDMGyr7X928uRJVatWzSlFXezi/f25hjZt2mjHjh2l2o6Pj498fHycXh8AAAAAAM5W6sDep08fSX+E54EDB9oF38LCQm3fvl1t2rRxanGBgYHy9PS0raZfcOzYsWKr7gAAAAAAXE9KHdj9/f0l/bG67evrqypVqtj6vL29dccdd+iJJ55wanHe3t6Kjo5WSkqK7r33Xlt7SkqKevXq5dR9AQAAAABgJqUO7HPnzpUkhYeH69lnn1XVqlWdUsDp06e1f/9+2/sDBw4oLS1NAQEBqlevnkaNGqW4uDi1bNlSrVu31uzZs3Xo0CENGTLEKfsHAAAAAMCMHL6G/dFHH9WRI0dUv359u/Yff/xRXl5eCg8Pd2h7mzdvtrtZ3ahRoyRJAwYMUHJysvr166eTJ09q0qRJysjIUGRkpJYsWaKwsDBHSwcAAAAAoNxwOLAPHDhQjz32WLHAvnHjRr399ttavXq1Q9uLiYmRYRiXHTNs2DANGzbM0VIBAAAAACi3HH6s27Zt29S2bdti7XfccYfS0tKcURMAAAAAABWew4HdYrEoNze3WHt2drYKCwudUhQAAAAAABWdw4G9ffv2SkpKsgvnhYWFSkpKUrt27ZxaHAAAAAAAFZXD17BPmzZNd955pxo0aKD27dtLktasWaOcnBytXLnS6QUCAAAAAFARObzC3rhxY23fvl19+/bVsWPHlJubq0cffVR79+5VZGSkK2oEAAAAAKDCcXiFXZKsVqsmT57s7FoAAAAAAMD/XFVgl6QzZ87o0KFDKigosGtv2rTpNRcFAAAAAEBF53BgP378uAYNGqSvvvqqxH7uFA8AAAAAwLVz+Br2+Ph4ZWVlacOGDapSpYqWLl2qefPmqX79+vrss89cUSMAAAAAABWOwyvsK1eu1KeffqrbbrtNHh4eCgsLU+fOneXn56ekpCT16NHDFXUCAAAAAFChOLzCnpeXp6CgIElSQECAjh8/Lklq0qSJtm7d6tzqAAAAAACooBwO7A0aNNC+ffskSc2aNdN//vMfHTlyRG+++aZq167t9AIBAAAAAKiIHD4lPj4+XhkZGZKkCRMmqGvXrvrggw/k7e2t5ORkZ9cHAAAAAECF5HBgf/jhh20/N2/eXAcPHtTevXtVr149BQYGOrU4AAAAAAAqKodPib+Yj4+PPDw85Onp6Yx6AAAAAACArvKxbnPmzJH0xzPX77zzTrVo0UKhoaFavXq1s+sDAAAAAKBCcjiw/9///Z+ioqIkSZ9//rntlPj4+HiNHz/e6QUCAAAAAFARORzYT5w4oZCQEEnSkiVL9MADD+iWW27R4MGDtWPHDqcXCAAAAABAReRwYA8ODtbu3btVWFiopUuX6u6775YknTlzhuvYAQAAAABwEofvEj9o0CD17dtXtWvXlsViUefOnSVJGzduVMOGDZ1eIAAAAAAAFZHDgT0xMVGRkZFKT0/XAw88IB8fH0mSp6enxo0b5/QCAQAAAACoiBwO7JJ0//33F2sbMGDANRcDAAAAAAD+cFWBfcWKFVqxYoWOHTumoqIiu7533nnHKYUBAAAAAFCRORzYJ06cqEmTJqlly5a269gBAAAAAIBzORzY33zzTSUnJysuLs4V9QAAAAAAAF3FY90KCgrUpk0bV9QCAAAAAAD+x+HA/vjjj2v+/PmuqAUAAAAAAPyPw6fE//7775o9e7aWL1+upk2bysvLy65/+vTpTisO7hU+7ssy3d/BKT3KdH8AAAAAYGYOB/bt27erWbNmkqSdO3fa9XEDOgAAAAAAnMPhwL5q1SpX1AEAAAAAAP7E4WvYAQAAAACA6zm8wi5JmzZt0scff6xDhw6poKDArm/hwoVOKQwAAAAAgIrM4RX2BQsWqG3bttq9e7cWLVqkc+fOaffu3Vq5cqX8/f1dUSMAAAAAABWOw4F98uTJevnll/XFF1/I29tbr776qvbs2aO+ffuqXr16rqjxsnJzc3XbbbepWbNmatKkid56660yrwEAAAAAAGdzOLD/9NNP6tHjj8dv+fj4KC8vTxaLRU8//bRmz57t9AKvpGrVqkpNTVVaWpo2btyopKQknTx5sszrAAAAAADAmRwO7AEBAcrNzZUk1alTx/Zot99++01nzpxxbnWl4OnpqapVq0r64xnxhYWFMgyjzOsAAAAAAMCZHA7s7du3V0pKiiSpb9++euqpp/TEE0/ooYceUqdOnRwu4JtvvlHPnj1ltVplsVi0ePHiYmNmzpypiIgIVa5cWdHR0VqzZo1d/2+//aaoqCjVrVtXY8aMUWBgoMN1AAAAAABgJg4H9hkzZujBBx+UJCUkJOiZZ57Rr7/+qj59+mjOnDkOF5CXl6eoqCjNmDGjxP6PPvpI8fHxGj9+vLZt26b27dure/fuOnTokG3MDTfcoO+//14HDhzQ/Pnz9euvv5a4rfz8fOXk5Ni9AAAAAAAwI4vhwPnj58+f1wcffKCuXbsqJCTE+cVYLFq0aJF69+5ta2vVqpVatGihWbNm2doaNWqk3r17Kykpqdg2hg4dqrvuuksPPPBAsb7ExERNnDixWHt2drb8/PyccxAuFD7uS3eX4FIHp/RwdwkAAAAA4FI5OTny9/cvVQ51aIW9UqVKGjp0qPLz86+pwNIqKCjQli1b1KVLF7v2Ll26aN26dZKkX3/91bZSnpOTo2+++UYNGjQocXsJCQnKzs62vdLT0117AAAAAAAAXKVKjv5Cq1attG3bNoWFhbmiHjsnTpxQYWGhgoOD7dqDg4OVmZkpSTp8+LAGDx4swzBkGIaGDx+upk2blrg9Hx8f+fj4uLxuAAAAAACulcOBfdiwYRo9erQOHz6s6OhoVatWza7/UmH5WlgsFrv3hmHY2qKjo5WWlub0fQIAAAAA4E6lDuyPPfaYXnnlFfXr10+SNHLkSFufxWKxhejCwkKnFRcYGChPT0/bavoFx44dK7bqDgAAAADA9aTUgX3evHmaMmWKDhw44Mp67Hh7eys6OlopKSm69957be0pKSnq1atXmdWBslHWN9XjJncAAAAAzKzUgf3CzeSdfe366dOntX//ftv7AwcOKC0tTQEBAapXr55GjRqluLg4tWzZUq1bt9bs2bN16NAhDRkyxKl1AAAAAABgJg5dw37xteTOsHnzZnXs2NH2ftSoUZKkAQMGKDk5Wf369dPJkyc1adIkZWRkKDIyUkuWLCmTm94BAAAAAOAupX4Ou4eHh/z9/a8Y2k+dOuWUwsqCI8+/M4Pr/TnsZY1T4gEAAACUNUdyqEMr7BMnTpS/v/81FQcAAAAAAK7MocD+4IMPKigoyFW1AAAAAACA//Eo7UBXXL8OAAAAAABKVurAXspL3QEAAAAAgBOU+pT4oqIiV9YBAAAAAAD+pNQr7AAAAAAAoOwQ2AEAAAAAMCGH7hIPXE/K+rn2PPcdAAAAgCNKtcLeokULZWVlSZImTZqkM2fOuLQoAAAAAAAqulIF9j179igvL0+SNHHiRJ0+fdqlRQEAAAAAUNGV6pT4Zs2aadCgQWrXrp0Mw9C///1vVa9evcSx//jHP5xaIAAAAAAAFVGpAntycrImTJigL774QhaLRV999ZUqVSr+qxaLhcAOAAAAAIATlCqwN2jQQAsWLJAkeXh4aMWKFQoKCnJpYQAAAAAAVGQO3yW+qKjIFXUAAAAAAIA/uarHuv3000965ZVXtGfPHlksFjVq1EhPPfWUbrrpJmfXB1w3yvoxchKPkgMAAADKs1LdJf7Pli1bpsaNG+u7775T06ZNFRkZqY0bN+rWW29VSkqKK2oEAAAAAKDCcXiFfdy4cXr66ac1ZcqUYu1jx45V586dnVYcAAAAAAAVlcMr7Hv27NHgwYOLtT/22GPavXu3U4oCAAAAAKCicziw16pVS2lpacXa09LSuHM8AAAAAABO4vAp8U888YT++te/6ueff1abNm1ksVi0du1aTZ06VaNHj3ZFjQAAAAAAVDgOB/a///3v8vX11UsvvaSEhARJktVqVWJiokaOHOn0AgEAAAAAqIgcDuwWi0VPP/20nn76aeXm5kqSfH19nV4YAAAAAAAV2VU9h/0CgjoAAAAAAK5xTYEdgLmFj/uyTPd3cEqPMt0fAAAAcD1z+C7xAAAAAADA9QjsAAAAAACYkEOB/dy5c+rYsaN++OEHV9UDAAAAAADkYGD38vLSzp07ZbFYXFUPAAAAAADQVZwS/+ijj2rOnDmuqAUAAAAAAPyPw3eJLygo0Ntvv62UlBS1bNlS1apVs+ufPn2604oDAAAAAKCicjiw79y5Uy1atJCkYteyc6o8AAAAAADO4XBgX7VqlSvqAHAd4LnvAAAAgPNc9WPd9u/fr2XLluns2bOSJMMwnFaUo+69917VqFFD999/v9tqAAAAAADAmRwO7CdPnlSnTp10yy236C9/+YsyMjIkSY8//rhGjx7t9AJLY+TIkXr33Xfdsm8AAAAAAFzB4cD+9NNPy8vLS4cOHVLVqlVt7f369dPSpUudWlxpdezYUb6+vm7ZNwAAAAAAruBwYP/66681depU1a1b1669fv36+uWXXxwu4JtvvlHPnj1ltVplsVi0ePHiYmNmzpypiIgIVa5cWdHR0VqzZo3D+wEAAAAAoDxxOLDn5eXZraxfcOLECfn4+DhcQF5enqKiojRjxowS+z/66CPFx8dr/Pjx2rZtm9q3b6/u3bvr0KFDDu8LAAAAAIDywuHAfuedd9pdL26xWFRUVKQXX3xRHTt2dLiA7t2764UXXlCfPn1K7J8+fboGDx6sxx9/XI0aNdIrr7yi0NBQzZo1y+F95efnKycnx+4FAAAAAIAZOfxYtxdffFExMTHavHmzCgoKNGbMGO3atUunTp3St99+69TiCgoKtGXLFo0bN86uvUuXLlq3bp3D20tKStLEiROdVR4AAAAAAC7jcGBv3Lixtm/frlmzZsnT01N5eXnq06ePnnzySdWuXdupxZ04cUKFhYUKDg62aw8ODlZmZqbtfdeuXbV161bl5eWpbt26WrRokW677bZi20tISNCoUaNs73NychQaGurUmgFcv3jOPAAAAMqSw4FdkkJCQsp0pdpisdi9NwzDrm3ZsmWl2o6Pj89VXWcPwJzKOkADAAAAZemqAntWVpbmzJmjPXv2yGKxqFGjRho0aJACAgKcWlxgYKA8PT3tVtMl6dixY8VW3QEAAAAAuJ44fNO51NRURURE6LXXXlNWVpZOnTql1157TREREUpNTXVqcd7e3oqOjlZKSopde0pKitq0aePUfQEAAAAAYCYOr7A/+eST6tu3r+0adkkqLCzUsGHD9OSTT2rnzp0Obe/06dPav3+/7f2BAweUlpamgIAA1atXT6NGjVJcXJxatmyp1q1ba/bs2Tp06JCGDBniaOkAUK6445R/rpsHAAAwD4cD+08//aRPPvnEFtYlydPTU6NGjbJ73Ftpbd682e5xcBduCjdgwAAlJyerX79+OnnypCZNmqSMjAxFRkZqyZIlCgsLc3hfAAAAAACUFw4H9hYtWmjPnj1q0KCBXfuePXvUrFkzhwuIiYmRYRiXHTNs2DANGzbM4W0DAAAAAFBelSqwb9++3fbzyJEj9dRTT2n//v264447JEkbNmzQG2+8oSlTprimSgAAAAAAKhiLcaXlbUkeHh6yWCxXXAm3WCwqLCx0WnGulpOTI39/f2VnZ8vPz8/d5VwRj7AC4Gpcww4AAOBajuTQUq2wHzhwwCmFAQAAAACA0ilVYOcGbwAAAAAAlC2HbzonSUeOHNG3336rY8eOqaioyK5v5MiRTikMAAAAAICKzOHAPnfuXA0ZMkTe3t6qWbOmLBaLrc9isRDYAQAAAABwAocD+z/+8Q/94x//UEJCgjw8PFxREwAAAAAAFZ7DifvMmTN68MEHCesAAAAAALiQwyvsgwcP1scff6xx48a5oh4AgBtd74+PLOvH1pX158lj+QD34797AM7kcGBPSkpSbGysli5dqiZNmsjLy8uuf/r06U4rDgAAAACAisrhwD558mQtW7ZMDRo0kKRiN50DAAAAAADXzuHAPn36dL3zzjsaOHCgC8oBAAAAAADSVdx0zsfHR23btnVFLQAAAAAA4H8cDuxPPfWUXn/9dVfUAgAAAAAA/sfhU+K/++47rVy5Ul988YVuvfXWYjedW7hwodOKAwAAAACgonI4sN9www3q06ePK2oBAADliDseA8gjrACgfOFRh9fG4cA+d+5cV9QBAAAAAAD+xOFr2AEAAAAAgOs5vMIeERFx2eet//zzz9dUEAAAAAAAuIrAHh8fb/f+3Llz2rZtm5YuXapnn33WWXUBAAAAAFChORzYn3rqqRLb33jjDW3evPmaCwIAAAAAAFcR2C+le/fuSkhIKFc3pTMMQ5KUk5Pj5kpKpyj/jLtLAIByray/78v6e/t6Pz6p/PxvNiqu6/2/e8BR/DdR3IUaL+TRy7EYpRlVCtOmTdPMmTN18OBBZ2yuTBw+fFihoaHuLgMAAAAAUMGkp6erbt26lx3j8Ap78+bN7W46ZxiGMjMzdfz4cc2cOdPxKt3IarUqPT1dvr6+l72Rnhnk5OQoNDRU6enp8vPzc3c5qOCYjzAb5iTMhPkIs2FOwkyYj39k6NzcXFmt1iuOdTiw9+7d2+69h4eHatWqpZiYGDVs2NDRzbmVh4fHFf+iYTZ+fn4VdmLDfJiPMBvmJMyE+QizYU7CTCr6fPT39y/VOIcD+4QJExwuBgAAAAAAOMbD3QUAAAAAAIDiSr3C7uHhccXrvC0Wi86fP3/NRaE4Hx8fTZgwQT4+Pu4uBWA+wnSYkzAT5iPMhjkJM2E+OqbUd4n/9NNPL9m3bt06vf766zIMQ2fPnnVacQAAAAAAVFTX9Fi3vXv3KiEhQZ9//rkefvhh/fOf/1S9evWcWR8AAAAAABXSVV3DfvToUT3xxBNq2rSpzp8/r23btmnevHmEdQAAAAAAnMShwJ6dna2xY8fq5ptv1q5du7RixQp9/vnnatKkiavqAwAAAACgQir1TeemTZumqVOnKiQkRB9++KF69erlyroAAAAAAKjQSr3CPm7cOP3++++6+eabNW/ePPXp06fEF5xv5syZioiIUOXKlRUdHa01a9a4uyRcBxITE2WxWOxeISEhtn7DMJSYmCir1aoqVaooJiZGu3btsttGfn6+RowYocDAQFWrVk333HOPDh8+bDcmKytLcXFx8vf3l7+/v+Li4vTbb7+VxSHCxL755hv17NlTVqtVFotFixcvtusvy/l36NAh9ezZU9WqVVNgYKBGjhypgoICVxw2TOxKc3LgwIHFvjPvuOMOuzHMSThLUlKSbrvtNvn6+iooKEi9e/fWvn377MbwPYmyUpr5yHek65Q6sD/66KPq27evAgICbB9gSS8410cffaT4+HiNHz9e27ZtU/v27dW9e3cdOnTI3aXhOnDrrbcqIyPD9tqxY4etb9q0aZo+fbpmzJihTZs2KSQkRJ07d1Zubq5tTHx8vBYtWqQFCxZo7dq1On36tGJjY1VYWGgb079/f6WlpWnp0qVaunSp0tLSFBcXV6bHCfPJy8tTVFSUZsyYUWJ/Wc2/wsJC9ejRQ3l5eVq7dq0WLFigTz75RKNHj3bdwcOUrjQnJalbt25235lLliyx62dOwllSU1P15JNPasOGDUpJSdH58+fVpUsX5eXl2cbwPYmyUpr5KPEd6TIGTO322283hgwZYtfWsGFDY9y4cW6qCNeLCRMmGFFRUSX2FRUVGSEhIcaUKVNsbb///rvh7+9vvPnmm4ZhGMZvv/1meHl5GQsWLLCNOXLkiOHh4WEsXbrUMAzD2L17tyHJ2LBhg23M+vXrDUnG3r17XXBUKI8kGYsWLbK9L8v5t2TJEsPDw8M4cuSIbcyHH35o+Pj4GNnZ2S45XpjfxXPSMAxjwIABRq9evS75O8xJuNKxY8cMSUZqaqphGHxPwr0uno+GwXekK13VXeJRNgoKCrRlyxZ16dLFrr1Lly5at26dm6rC9eTHH3+U1WpVRESEHnzwQf3888+SpAMHDigzM9Nu7vn4+KhDhw62ubdlyxadO3fObozValVkZKRtzPr16+Xv769WrVrZxtxxxx3y9/dnDuOSynL+rV+/XpGRkbJarbYxXbt2VX5+vrZs2eLS40T5s3r1agUFBemWW27RE088oWPHjtn6mJNwpezsbElSQECAJL4n4V4Xz8cL+I50DQK7iZ04cUKFhYUKDg62aw8ODlZmZqabqsL1olWrVnr33Xe1bNkyvfXWW8rMzFSbNm108uRJ2/y63NzLzMyUt7e3atSocdkxQUFBxfYdFBTEHMYlleX8y8zMLLafGjVqyNvbmzkKO927d9cHH3yglStX6qWXXtKmTZt01113KT8/XxJzEq5jGIZGjRqldu3aKTIyUhLfk3CfkuajxHekK5X6LvFwH4vFYvfeMIxibYCjunfvbvu5SZMmat26tW666SbNmzfPdpOQq5l7F48paTxzGKVRVvOPOYrS6Nevn+3nyMhItWzZUmFhYfryyy8ve9Nd5iSu1fDhw7V9+3atXbu2WB/fkyhrl5qPfEe6DivsJhYYGChPT89ify06duxYsb8sAdeqWrVqatKkiX788Ufb3eIvN/dCQkJUUFCgrKysy4759ddfi+3r+PHjzGFcUlnOv5CQkGL7ycrK0rlz55ijuKzatWsrLCxMP/74oyTmJFxjxIgR+uyzz7Rq1SrVrVvX1s73JNzhUvOxJHxHOg+B3cS8vb0VHR2tlJQUu/aUlBS1adPGTVXhepWfn689e/aodu3aioiIUEhIiN3cKygoUGpqqm3uRUdHy8vLy25MRkaGdu7caRvTunVrZWdn67vvvrON2bhxo7Kzs5nDuKSynH+tW7fWzp07lZGRYRvz9ddfy8fHR9HR0S49TpRvJ0+eVHp6umrXri2JOQnnMgxDw4cP18KFC7Vy5UpFRETY9fM9ibJ0pflYEr4jnags73AHxy1YsMDw8vIy5syZY+zevduIj483qlWrZhw8eNDdpaGcGz16tLF69Wrj559/NjZs2GDExsYavr6+trk1ZcoUw9/f31i4cKGxY8cO46GHHjJq165t5OTk2LYxZMgQo27dusby5cuNrVu3GnfddZcRFRVlnD9/3jamW7duRtOmTY3169cb69evN5o0aWLExsaW+fHCXHJzc41t27YZ27ZtMyQZ06dPN7Zt22b88ssvhmGU3fw7f/68ERkZaXTq1MnYunWrsXz5cqNu3brG8OHDy+7DgClcbk7m5uYao0ePNtatW2ccOHDAWLVqldG6dWujTp06zEm4xNChQw1/f39j9erVRkZGhu115swZ2xi+J1FWrjQf+Y50LQJ7OfDGG28YYWFhhre3t9GiRQu7RygAV6tfv35G7dq1DS8vL8NqtRp9+vQxdu3aZesvKioyJkyYYISEhBg+Pj7GnXfeaezYscNuG2fPnjWGDx9uBAQEGFWqVDFiY2ONQ4cO2Y05efKk8fDDDxu+vr6Gr6+v8fDDDxtZWVllcYgwsVWrVhmSir0GDBhgGEbZzr9ffvnF6NGjh1GlShUjICDAGD58uPH777+78vBhQpebk2fOnDG6dOli1KpVy/Dy8jLq1atnDBgwoNh8Y07CWUqai5KMuXPn2sbwPYmycqX5yHeka1kMwzDKbj0fAAAAAACUBtewAwAAAABgQgR2AAAAAABMiMAOAAAAAIAJEdgBAAAAADAhAjsAAAAAACZEYAcAAAAAwIQI7AAAAAAAmBCBHQAAAAAAEyKwAwAAAABgQgR2AACuU+vWrZOnp6e6devm7lIcEhMTo/j4eHeXAQCA2xHYAQC4Tr3zzjsaMWKE1q5dq0OHDrm7HAAA4CACOwAA16G8vDz997//1dChQxUbG6vk5GRb3+rVq2WxWLRs2TI1b95cVapU0V133aVjx47pq6++UqNGjeTn56eHHnpIZ86csf1efn6+Ro4cqaCgIFWuXFnt2rXTpk2bbP3Jycm64YYb7OpYvHixLBaL7X1iYqKaNWum9957T+Hh4fL399eDDz6o3NxcSdLAgQOVmpqqV199VRaLRRaLRQcPHnTJZwQAgNkR2AEAuA599NFHatCggRo0aKBHHnlEc+fOlWEYdmMSExM1Y8YMrVu3Tunp6erbt69eeeUVzZ8/X19++aVSUlL0+uuv28aPGTNGn3zyiebNm6etW7fq5ptvVteuXXXq1CmHavvpp5+0ePFiffHFF/riiy+UmpqqKVOmSJJeffVVtW7dWk888YQyMjKUkZGh0NDQa/9AAAAohwjsAABch+bMmaNHHnlEktStWzedPn1aK1assBvzwgsvqG3btmrevLkGDx6s1NRUzZo1S82bN1f79u11//33a9WqVZL+WLGfNWuWXnzxRXXv3l2NGzfWW2+9pSpVqmjOnDkO1VZUVKTk5GRFRkaqffv2iouLs9Xm7+8vb29vVa1aVSEhIQoJCZGnp6cTPhEAAMofAjsAANeZffv26bvvvtODDz4oSapUqZL69eund955x25c06ZNbT8HBweratWquvHGG+3ajh07JumPVfFz586pbdu2tn4vLy/dfvvt2rNnj0P1hYeHy9fX1/a+du3atv0AAID/r5K7CwAAAM41Z84cnT9/XnXq1LG1GYYhLy8vZWVl2dq8vLxsP1ssFrv3F9qKiopsv3+h7c8Mw7C1eXh4FDvt/ty5c8Xqu9x+AADA/8cKOwAA15Hz58/r3Xff1UsvvaS0tDTb6/vvv1dYWJg++OCDq9ruzTffLG9vb61du9bWdu7cOW3evFmNGjWSJNWqVUu5ubnKy8uzjUlLS3N4X97e3iosLLyqOgEAuJ6wwg4AwHXkiy++UFZWlgYPHix/f3+7vvvvv19z5szRyy+/7PB2q1WrpqFDh+rZZ59VQECA6tWrp2nTpunMmTMaPHiwJKlVq1aqWrWqnnvuOY0YMULfffed3d3pSys8PFwbN27UwYMHVb16dQUEBMjDgzUGAEDFw//6AQBwHZkzZ47uvvvuYmFdku677z6lpaVp69atV7XtKVOm6L777lNcXJxatGih/fv3a9myZapRo4YkKSAgQO+//76WLFmiJk2a6MMPP1RiYqLD+3nmmWfk6empxo0bq1atWjxDHgBQYVmMiy82AwAAAAAAbscKOwAAAAAAJkRgBwAAAADAhAjsAAAAAACYEIEdAAAAAAATIrADAAAAAGBCBHYAAAAAAEyIwA4AAAAAgAkR2AEAAAAAMCECOwAAAAAAJkRgBwAAAADAhAjsAAAAAACY0P8D+kCJ7ues0L0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (axis_1, axis_2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "\n",
    "bins = 30\n",
    "\n",
    "axis_1.hist(df.Amount[df.Class == 1], bins = bins)\n",
    "axis_1.set_title('Fraud')\n",
    "\n",
    "axis_2.hist(df.Amount[df.Class == 0], bins = bins)\n",
    "axis_2.set_title('Normal (Non-Fraud)')\n",
    "\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210b5cd",
   "metadata": {},
   "source": [
    "We can see here that fraud transactions are of smaller amount. but this cant be used solely because normal transactions \n",
    "too have a lot of transactions of smaller amount. so this kind of helps in a sense that we can say that if the amount\n",
    "is not large then its 'probably' not a fraud transaction, but obviously, fraud and normal transactions cant be \n",
    "distinguished only according to amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd1cca",
   "metadata": {},
   "source": [
    "Identifying Categorical Columns: The categorical columns of the dataset are identified.\n",
    "Separating Classes: The dataset is split into minority (fraudulent transactions) and majority (non-fraudulent transactions) classes.\n",
    "Training CTGAN Model: A **CTGAN** (Conditional Tabular GAN) model is created and trained using only the minority class data to learn its distribution.\n",
    "Generating Synthetic Samples: The model generates synthetic samples to balance the dataset by creating a number of minority class samples equal to the difference between the majority and minority class counts.\n",
    "Combining Data: The original dataset is combined with the synthetic samples to create a balanced dataset.\n",
    "Class Distribution: The class distribution of the newly balanced dataset is displayed to confirm the balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b46e186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1    284315\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as it is highly imbalanced dataset need to balance it using gans\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "minority_class = df[df['Class'] == 1]\n",
    "majority_class = df[df['Class'] == 0]\n",
    "\n",
    "\n",
    "# Create and train the CTGAN model on the minority class\n",
    "ctgan = CTGAN(epochs=100)\n",
    "ctgan.fit(minority_class)\n",
    "\n",
    "\n",
    "num_samples_to_generate = len(majority_class) - len(minority_class)\n",
    "synthetic_samples = ctgan.sample(num_samples_to_generate)\n",
    "\n",
    "\n",
    "df = pd.concat([df, synthetic_samples], ignore_index=True)\n",
    "\n",
    "\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f854e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "# Import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting feature variables into X\n",
    "X = df.drop(['Class'], axis=1)\n",
    "\n",
    "# Putting target variable to y\n",
    "y = df['Class']\n",
    "\n",
    "# Splitting data into train and test set 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64ea4c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28447</th>\n",
       "      <td>35016.000000</td>\n",
       "      <td>0.655598</td>\n",
       "      <td>-2.023127</td>\n",
       "      <td>-0.473715</td>\n",
       "      <td>-0.605063</td>\n",
       "      <td>-1.048013</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>-0.218741</td>\n",
       "      <td>-0.156654</td>\n",
       "      <td>-0.478045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.518153</td>\n",
       "      <td>0.432995</td>\n",
       "      <td>-0.690983</td>\n",
       "      <td>-0.952536</td>\n",
       "      <td>0.573506</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>-0.072004</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>1.400716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493667</th>\n",
       "      <td>76262.602179</td>\n",
       "      <td>1.897229</td>\n",
       "      <td>15.150918</td>\n",
       "      <td>-8.710520</td>\n",
       "      <td>5.506679</td>\n",
       "      <td>-15.230535</td>\n",
       "      <td>-1.349399</td>\n",
       "      <td>-0.792086</td>\n",
       "      <td>-2.531548</td>\n",
       "      <td>2.853378</td>\n",
       "      <td>...</td>\n",
       "      <td>3.446232</td>\n",
       "      <td>0.074633</td>\n",
       "      <td>0.792638</td>\n",
       "      <td>1.029654</td>\n",
       "      <td>-0.556467</td>\n",
       "      <td>-0.967202</td>\n",
       "      <td>-0.127558</td>\n",
       "      <td>-0.401563</td>\n",
       "      <td>0.695180</td>\n",
       "      <td>0.022347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363558</th>\n",
       "      <td>92239.910057</td>\n",
       "      <td>-5.944378</td>\n",
       "      <td>0.161574</td>\n",
       "      <td>-8.236963</td>\n",
       "      <td>4.429474</td>\n",
       "      <td>2.698580</td>\n",
       "      <td>-2.755864</td>\n",
       "      <td>3.272621</td>\n",
       "      <td>7.473681</td>\n",
       "      <td>1.420285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701150</td>\n",
       "      <td>-1.511130</td>\n",
       "      <td>0.153699</td>\n",
       "      <td>-0.560640</td>\n",
       "      <td>-0.126482</td>\n",
       "      <td>0.331073</td>\n",
       "      <td>1.197980</td>\n",
       "      <td>0.134714</td>\n",
       "      <td>0.600326</td>\n",
       "      <td>-0.190255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217453</th>\n",
       "      <td>140894.000000</td>\n",
       "      <td>2.166772</td>\n",
       "      <td>-0.518305</td>\n",
       "      <td>-1.231390</td>\n",
       "      <td>-0.291323</td>\n",
       "      <td>-0.459410</td>\n",
       "      <td>-1.083303</td>\n",
       "      <td>-0.179789</td>\n",
       "      <td>-0.436250</td>\n",
       "      <td>-0.451792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.559318</td>\n",
       "      <td>-0.043483</td>\n",
       "      <td>0.603334</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-0.068698</td>\n",
       "      <td>0.274296</td>\n",
       "      <td>-0.016204</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>-0.051562</td>\n",
       "      <td>-0.424689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93673</th>\n",
       "      <td>64538.000000</td>\n",
       "      <td>1.287888</td>\n",
       "      <td>-0.338171</td>\n",
       "      <td>-0.853423</td>\n",
       "      <td>-1.068883</td>\n",
       "      <td>1.662317</td>\n",
       "      <td>3.342280</td>\n",
       "      <td>-0.841614</td>\n",
       "      <td>0.871857</td>\n",
       "      <td>0.247240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097036</td>\n",
       "      <td>-0.237722</td>\n",
       "      <td>-0.882660</td>\n",
       "      <td>0.105775</td>\n",
       "      <td>1.037183</td>\n",
       "      <td>0.164507</td>\n",
       "      <td>0.802175</td>\n",
       "      <td>-0.062745</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>-0.388254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time        V1         V2        V3        V4         V5  \\\n",
       "28447    35016.000000  0.655598  -2.023127 -0.473715 -0.605063  -1.048013   \n",
       "493667   76262.602179  1.897229  15.150918 -8.710520  5.506679 -15.230535   \n",
       "363558   92239.910057 -5.944378   0.161574 -8.236963  4.429474   2.698580   \n",
       "217453  140894.000000  2.166772  -0.518305 -1.231390 -0.291323  -0.459410   \n",
       "93673    64538.000000  1.287888  -0.338171 -0.853423 -1.068883   1.662317   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "28447   0.003242 -0.218741 -0.156654 -0.478045  ...  0.969345  0.518153   \n",
       "493667 -1.349399 -0.792086 -2.531548  2.853378  ...  3.446232  0.074633   \n",
       "363558 -2.755864  3.272621  7.473681  1.420285  ...  0.701150 -1.511130   \n",
       "217453 -1.083303 -0.179789 -0.436250 -0.451792  ... -0.559318 -0.043483   \n",
       "93673   3.342280 -0.841614  0.871857  0.247240  ...  0.097036 -0.237722   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "28447   0.432995 -0.690983 -0.952536  0.573506  0.016336 -0.072004  0.077913   \n",
       "493667  0.792638  1.029654 -0.556467 -0.967202 -0.127558 -0.401563  0.695180   \n",
       "363558  0.153699 -0.560640 -0.126482  0.331073  1.197980  0.134714  0.600326   \n",
       "217453  0.603334 -0.009257 -0.068698  0.274296 -0.016204  0.019198 -0.051562   \n",
       "93673  -0.882660  0.105775  1.037183  0.164507  0.802175 -0.062745  0.010789   \n",
       "\n",
       "          Amount  \n",
       "28447   1.400716  \n",
       "493667  0.022347  \n",
       "363558 -0.190255  \n",
       "217453 -0.424689  \n",
       "93673  -0.388254  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling features \n",
    "\n",
    "# Standardization method\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the data into scaler and transform\n",
    "X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37d5b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309550</th>\n",
       "      <td>63558.330208</td>\n",
       "      <td>0.644382</td>\n",
       "      <td>-13.565181</td>\n",
       "      <td>-11.952039</td>\n",
       "      <td>15.109823</td>\n",
       "      <td>1.202077</td>\n",
       "      <td>1.847472</td>\n",
       "      <td>0.314838</td>\n",
       "      <td>-2.714038</td>\n",
       "      <td>0.878398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.165083</td>\n",
       "      <td>-0.998505</td>\n",
       "      <td>-1.647710</td>\n",
       "      <td>0.919619</td>\n",
       "      <td>-0.207921</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>-0.087625</td>\n",
       "      <td>-1.111587</td>\n",
       "      <td>-0.595027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418331</th>\n",
       "      <td>143775.675901</td>\n",
       "      <td>4.593819</td>\n",
       "      <td>-0.496097</td>\n",
       "      <td>-4.866179</td>\n",
       "      <td>10.753131</td>\n",
       "      <td>-2.059626</td>\n",
       "      <td>-5.001183</td>\n",
       "      <td>-0.492600</td>\n",
       "      <td>-0.991095</td>\n",
       "      <td>-5.821277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583260</td>\n",
       "      <td>-0.972575</td>\n",
       "      <td>-1.157151</td>\n",
       "      <td>-0.202277</td>\n",
       "      <td>-0.529507</td>\n",
       "      <td>0.345160</td>\n",
       "      <td>0.172214</td>\n",
       "      <td>0.107798</td>\n",
       "      <td>0.444198</td>\n",
       "      <td>0.317327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313225</th>\n",
       "      <td>54552.610709</td>\n",
       "      <td>-0.625399</td>\n",
       "      <td>-1.836775</td>\n",
       "      <td>-10.153936</td>\n",
       "      <td>14.215980</td>\n",
       "      <td>-0.020237</td>\n",
       "      <td>-3.635993</td>\n",
       "      <td>-6.694761</td>\n",
       "      <td>-6.694274</td>\n",
       "      <td>-0.912539</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046508</td>\n",
       "      <td>-0.701405</td>\n",
       "      <td>0.281268</td>\n",
       "      <td>-1.521371</td>\n",
       "      <td>0.746258</td>\n",
       "      <td>0.539720</td>\n",
       "      <td>-0.536287</td>\n",
       "      <td>-2.924539</td>\n",
       "      <td>-0.011326</td>\n",
       "      <td>0.259675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354977</th>\n",
       "      <td>118566.826142</td>\n",
       "      <td>1.027145</td>\n",
       "      <td>0.372199</td>\n",
       "      <td>-9.701289</td>\n",
       "      <td>14.471264</td>\n",
       "      <td>-1.013641</td>\n",
       "      <td>2.112740</td>\n",
       "      <td>-13.711740</td>\n",
       "      <td>-6.973724</td>\n",
       "      <td>-4.122157</td>\n",
       "      <td>...</td>\n",
       "      <td>2.358247</td>\n",
       "      <td>-7.030398</td>\n",
       "      <td>0.513372</td>\n",
       "      <td>0.930622</td>\n",
       "      <td>-0.114701</td>\n",
       "      <td>0.445429</td>\n",
       "      <td>-0.204847</td>\n",
       "      <td>-0.540462</td>\n",
       "      <td>1.051537</td>\n",
       "      <td>0.081041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43690</th>\n",
       "      <td>41614.000000</td>\n",
       "      <td>-0.139161</td>\n",
       "      <td>-2.902640</td>\n",
       "      <td>-1.003477</td>\n",
       "      <td>-0.910175</td>\n",
       "      <td>-1.245766</td>\n",
       "      <td>-0.214458</td>\n",
       "      <td>0.723494</td>\n",
       "      <td>-0.155300</td>\n",
       "      <td>1.524544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379084</td>\n",
       "      <td>0.225217</td>\n",
       "      <td>-0.882590</td>\n",
       "      <td>-0.800878</td>\n",
       "      <td>-0.446879</td>\n",
       "      <td>0.346636</td>\n",
       "      <td>-0.143507</td>\n",
       "      <td>-0.145894</td>\n",
       "      <td>0.121366</td>\n",
       "      <td>2.708489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time        V1         V2         V3         V4        V5  \\\n",
       "309550   63558.330208  0.644382 -13.565181 -11.952039  15.109823  1.202077   \n",
       "418331  143775.675901  4.593819  -0.496097  -4.866179  10.753131 -2.059626   \n",
       "313225   54552.610709 -0.625399  -1.836775 -10.153936  14.215980 -0.020237   \n",
       "354977  118566.826142  1.027145   0.372199  -9.701289  14.471264 -1.013641   \n",
       "43690    41614.000000 -0.139161  -2.902640  -1.003477  -0.910175 -1.245766   \n",
       "\n",
       "              V6         V7        V8        V9  ...       V20       V21  \\\n",
       "309550  1.847472   0.314838 -2.714038  0.878398  ...  0.433163  0.165083   \n",
       "418331 -5.001183  -0.492600 -0.991095 -5.821277  ...  0.583260 -0.972575   \n",
       "313225 -3.635993  -6.694761 -6.694274 -0.912539  ...  1.046508 -0.701405   \n",
       "354977  2.112740 -13.711740 -6.973724 -4.122157  ...  2.358247 -7.030398   \n",
       "43690  -0.214458   0.723494 -0.155300  1.524544  ...  1.379084  0.225217   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "309550 -0.998505 -1.647710  0.919619 -0.207921  0.997216 -0.087625 -1.111587   \n",
       "418331 -1.157151 -0.202277 -0.529507  0.345160  0.172214  0.107798  0.444198   \n",
       "313225  0.281268 -1.521371  0.746258  0.539720 -0.536287 -2.924539 -0.011326   \n",
       "354977  0.513372  0.930622 -0.114701  0.445429 -0.204847 -0.540462  1.051537   \n",
       "43690  -0.882590 -0.800878 -0.446879  0.346636 -0.143507 -0.145894  0.121366   \n",
       "\n",
       "          Amount  \n",
       "309550 -0.595027  \n",
       "418331  0.317327  \n",
       "313225  0.259675  \n",
       "354977  0.081041  \n",
       "43690   2.708489  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test set\n",
    "X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd9ce8",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e06f32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8df9dae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.609324</td>\n",
       "      <td>0.537608</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999732</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.825187</td>\n",
       "      <td>0.400512</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.999797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.746949</td>\n",
       "      <td>0.479377</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.999765</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.872002</td>\n",
       "      <td>0.149653</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.011685</td>\n",
       "      <td>0.105472</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.970822</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       2.609324      0.537608         0.025638        0.000811    0.01   \n",
       "1       2.825187      0.400512         0.026431        0.002637     0.1   \n",
       "2       2.746949      0.479377         0.025638        0.000925       1   \n",
       "3       2.872002      0.149653         0.025136        0.000976      10   \n",
       "4       3.011685      0.105472         0.028633        0.003768     100   \n",
       "5       2.970822      0.085233         0.026733        0.001684    1000   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.01}           0.999783           0.999732           0.999663   \n",
       "1   {'C': 0.1}           0.999803           0.999717           0.999658   \n",
       "2     {'C': 1}           0.999813           0.999687           0.999660   \n",
       "3    {'C': 10}           0.999804           0.999718           0.999663   \n",
       "4   {'C': 100}           0.999808           0.999728           0.999663   \n",
       "5  {'C': 1000}           0.999813           0.999722           0.999699   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.999796  ...         0.999749        0.000048                6   \n",
       "1           0.999797  ...         0.999761        0.000064                1   \n",
       "2           0.999825  ...         0.999761        0.000072                2   \n",
       "3           0.999797  ...         0.999751        0.000054                5   \n",
       "4           0.999795  ...         0.999755        0.000053                4   \n",
       "5           0.999810  ...         0.999761        0.000046                3   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.999728            0.999788            0.999768   \n",
       "1            0.999745            0.999772            0.999764   \n",
       "2            0.999763            0.999759            0.999775   \n",
       "3            0.999747            0.999773            0.999777   \n",
       "4            0.999758            0.999794            0.999777   \n",
       "5            0.999764            0.999790            0.999780   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.999725            0.999742          0.999750         0.000024  \n",
       "1            0.999771            0.999792          0.999769         0.000015  \n",
       "2            0.999759            0.999769          0.999765         0.000007  \n",
       "3            0.999771            0.999749          0.999763         0.000013  \n",
       "4            0.999771            0.999751          0.999770         0.000015  \n",
       "5            0.999783            0.999735          0.999770         0.000020  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of grid search CV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb0d6165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The highest test roc_auc is 0.999761391599862 at C = 0.1\n"
     ]
    }
   ],
   "source": [
    "# Best score with best C\n",
    "best_score = model_cv.best_score_\n",
    "best_C = model_cv.best_params_['C']\n",
    "\n",
    "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "769ae7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227333    402]\n",
      " [   264 226905]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression with optimal C\n",
    "\n",
    "# Instantiate the model with best C\n",
    "logistic_bal_rus = LogisticRegression(C=0.01)\n",
    "\n",
    "# Fit the model on the train set\n",
    "logistic_bal_rus_model = logistic_bal_rus.fit(X_train, y_train)\n",
    "# Predictions on the train set\n",
    "y_train_pred = logistic_bal_rus_model.predict(X_train)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c1a0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99f63d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:- 1.0\n",
      "Sensitivity:- 0.9988378696036871\n",
      "Specificity:- 0.9982347904362526\n",
      "F1-Score:- 0.9985345760832255\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# F1 score\n",
    "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "487ab92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227735\n",
      "           1       1.00      1.00      1.00    227169\n",
      "\n",
      "    accuracy                           1.00    454904\n",
      "   macro avg       1.00      1.00      1.00    454904\n",
      "weighted avg       1.00      1.00      1.00    454904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report\n",
    "print(classification_report(y_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "897eda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "y_test_pred = logistic_bal_rus_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4838bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56465   115]\n",
      " [   59 57087]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c01a12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9d21787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:- 0.99847000685859\n",
      "Sensitivity:- 0.9989675567843769\n",
      "Specificity:- 0.9979674796747967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56580\n",
      "           1       1.00      1.00      1.00     57146\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c42b4",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "High Performance: The model demonstrates excellent performance across all metrics, indicating its robustness and reliability in identifying both fraudulent and non-fraudulent transactions.\n",
    "Balanced Classification: With high precision, recall, and F1-scores for both classes, the model is well-balanced and effective at minimizing both false positives and false negatives.\n",
    "Potential Overfitting: Such high metrics might suggest overfitting, especially if this performance is measured on the training set. It's crucial to validate the model's performance on a separate test set to ensure it generalizes well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b9797",
   "metadata": {},
   "source": [
    "**XgBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "653884d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=2,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=200,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.2, 0.6],\n",
       "                         'subsample': [0.3, 0.6, 0.9]},\n",
       "             return_train_score=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgboost\n",
    "\n",
    "# Importing XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "858d756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.374151</td>\n",
       "      <td>0.194354</td>\n",
       "      <td>0.118323</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.3}</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>8.937584e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.147832</td>\n",
       "      <td>0.094396</td>\n",
       "      <td>0.104563</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.6}</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>4.061197e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.174055</td>\n",
       "      <td>0.131871</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.9}</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2.636835e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.273906</td>\n",
       "      <td>0.131068</td>\n",
       "      <td>0.106901</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.3}</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.497283e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.170884</td>\n",
       "      <td>0.114403</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.6}</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.200844e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.287515</td>\n",
       "      <td>0.087934</td>\n",
       "      <td>0.104566</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.9}</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.374151      0.194354         0.118323        0.013019   \n",
       "1       2.147832      0.094396         0.104563        0.009648   \n",
       "2       2.174055      0.131871         0.110385        0.009982   \n",
       "3       2.273906      0.131068         0.106901        0.009091   \n",
       "4       2.170884      0.114403         0.102899        0.009508   \n",
       "5       2.287515      0.087934         0.104566        0.010180   \n",
       "\n",
       "  param_learning_rate param_subsample  \\\n",
       "0                 0.2             0.3   \n",
       "1                 0.2             0.6   \n",
       "2                 0.2             0.9   \n",
       "3                 0.6             0.3   \n",
       "4                 0.6             0.6   \n",
       "5                 0.6             0.9   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.2, 'subsample': 0.3}           0.999949   \n",
       "1  {'learning_rate': 0.2, 'subsample': 0.6}           0.999950   \n",
       "2  {'learning_rate': 0.2, 'subsample': 0.9}           0.999947   \n",
       "3  {'learning_rate': 0.6, 'subsample': 0.3}           0.999939   \n",
       "4  {'learning_rate': 0.6, 'subsample': 0.6}           0.999942   \n",
       "5  {'learning_rate': 0.6, 'subsample': 0.9}           0.999936   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.999966           0.999966         0.999960        0.000008   \n",
       "1           0.999965           0.999954         0.999956        0.000006   \n",
       "2           0.999974           0.999958         0.999960        0.000011   \n",
       "3           0.999928           0.999949         0.999939        0.000008   \n",
       "4           0.999960           0.999953         0.999952        0.000007   \n",
       "5           0.999968           0.999953         0.999952        0.000013   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.999998            0.999998   \n",
       "1                3            0.999999            0.999999   \n",
       "2                2            0.999999            0.999999   \n",
       "3                6            1.000000            1.000000   \n",
       "4                5            1.000000            1.000000   \n",
       "5                4            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.999996          0.999997     8.937584e-07  \n",
       "1            0.999998          0.999999     4.061197e-07  \n",
       "2            0.999999          0.999999     2.636835e-07  \n",
       "3            1.000000          1.000000     1.497283e-07  \n",
       "4            1.000000          1.000000     8.200844e-11  \n",
       "5            1.000000          1.000000     0.000000e+00  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a82fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'subsample': 0.3}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a387bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:08:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"params\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None,\n",
       "              params={'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200,\n",
       "                      'objective': 'binary:logistic', 'subsample': 0.9}, ...)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chosen hyperparameters\n",
    "# 'objective':'binary:logistic' outputs probability rather than label, which we need for calculating auc\n",
    "params = {'learning_rate': 0.2,\n",
    "          'max_depth': 2, \n",
    "          'n_estimators':200,\n",
    "          'subsample':0.9,\n",
    "         'objective':'binary:logistic'}\n",
    "\n",
    "# fit model on training data\n",
    "xgb_imb_model = XGBClassifier(params = params)\n",
    "xgb_imb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38a1fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227735      0]\n",
      " [     0 227169]]\n",
      "Accuracy:- 1.0\n",
      "Sensitivity:- 1.0\n",
      "Specificity:- 1.0\n",
      "F1-Score:- 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    227735\n",
      "           1       1.00      1.00      1.00    227169\n",
      "\n",
      "    accuracy                           1.00    454904\n",
      "   macro avg       1.00      1.00      1.00    454904\n",
      "weighted avg       1.00      1.00      1.00    454904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = xgb_imb_model.predict(X_train)\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion)\n",
    "\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# F1 score\n",
    "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "58e505cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56572     8]\n",
      " [   18 57128]]\n",
      "Accuracy:- 0.9997713803351916\n",
      "Sensitivity:- 0.9996850173240471\n",
      "Specificity:- 0.999858607281725\n",
      "F1-Score:- 0.9997724926060098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56580\n",
      "           1       1.00      1.00      1.00     57146\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on the test set\n",
    "y_test_pred = xgb_imb_model.predict(X_test)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = xgb_imb_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# F1 score\n",
    "print(\"F1-Score:-\", f1_score(y_test, y_test_pred))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291db3de",
   "metadata": {},
   "source": [
    "1.\tConfusion Matrix:\n",
    "o\tTrue Negatives (TN): 56,572\n",
    "o\tFalse Positives (FP): 8\n",
    "o\tFalse Negatives (FN): 17\n",
    "o\tTrue Positives (TP): 57,129\n",
    "2.\tAccuracy:\n",
    "o\tThe model achieves an accuracy of 99.98%, indicating that it correctly classifies 99.98% of the transactions. This high accuracy suggests the model is very effective at distinguishing between fraudulent and non-fraudulent transactions.\n",
    "3.\tSensitivity (Recall) for Class 1 (Fraudulent Transactions):\n",
    "o\tThe sensitivity is 99.97%, meaning the model successfully identifies 99.97% of actual fraudulent transactions. This is crucial for minimizing the number of fraudulent transactions that go undetected.\n",
    "4.\tSpecificity for Class 0 (Non-Fraudulent Transactions):\n",
    "o\tThe specificity is 99.99%, indicating the model correctly identifies 99.99% of non-fraudulent transactions, thus minimizing the number of legitimate transactions flagged as fraudulent.\n",
    "5.\tPrecision:\n",
    "o\tPrecision for both classes is very high (1.00), suggesting that when the model predicts a transaction as fraudulent or non-fraudulent, it is almost always correct.\n",
    "6.\tF1-Score:\n",
    "o\tThe F1-score is 0.99978 for fraudulent transactions, reflecting a good balance between precision and recall.\n",
    "7.\tClassification Report:\n",
    "o\tThe report shows extremely high precision, recall, and F1-scores for both classes, indicating that the model performs well across all these metrics.\n",
    "Conclusion:\n",
    "•\tHigh Performance: The model demonstrates excellent performance with near-perfect metrics, indicating robustness and reliability in identifying both fraudulent and non-fraudulent transactions.\n",
    "•\tBalanced Classification: The model maintains high precision, recall, and F1-scores for both classes, effectively balancing false positives and false negatives.\n",
    "•\tPotential Overfitting: Such high metrics might suggest overfitting, especially if this performance is measured on the training set. It is crucial to validate the model's performance on a separate test set to ensure it generalizes well to new, unseen data.\n",
    "Overall, the XGBoost model is highly effective for this fraud detection task, making it a strong candidate for deployment in a real-world scenario, provided it also performs well on validation and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667eddc",
   "metadata": {},
   "source": [
    "**Generating Synthetic Data using oversampling of the minority classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ff03182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\irfan\\Downloads\\archive\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "43a8f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing oversampler library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1276b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variables into X\n",
    "X = df.drop(['Class'], axis=1)\n",
    "\n",
    "# Putting target variable to y\n",
    "y = df['Class']\n",
    "\n",
    "# Splitting data into train and test set 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6bbd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the random oversampler \n",
    "ros = RandomOverSampler()\n",
    "# resampling X, y\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cfb1c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling class distribution:- Counter({0: 227449, 1: 396})\n",
      "New class distribution:- Counter({0: 227449, 1: 227449})\n"
     ]
    }
   ],
   "source": [
    "# Befor sampling class distribution\n",
    "print('Before sampling class distribution:-',Counter(y_train))\n",
    "# new class distribution \n",
    "print('New class distribution:-',Counter(y_train_ros))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be843a5",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "13c9d2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\irfan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             return_train_score=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as roc-auc\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train_ros, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91e17e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.478978</td>\n",
       "      <td>0.589159</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.982989</td>\n",
       "      <td>0.984116</td>\n",
       "      <td>0.978833</td>\n",
       "      <td>0.979320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977418</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982914</td>\n",
       "      <td>0.984019</td>\n",
       "      <td>0.979441</td>\n",
       "      <td>0.979479</td>\n",
       "      <td>0.961078</td>\n",
       "      <td>0.977386</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.354008</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.983998</td>\n",
       "      <td>0.979272</td>\n",
       "      <td>0.981737</td>\n",
       "      <td>0.979341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977261</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983972</td>\n",
       "      <td>0.979338</td>\n",
       "      <td>0.982457</td>\n",
       "      <td>0.979500</td>\n",
       "      <td>0.961205</td>\n",
       "      <td>0.977295</td>\n",
       "      <td>0.008236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.321863</td>\n",
       "      <td>0.534556</td>\n",
       "      <td>0.022885</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.979453</td>\n",
       "      <td>0.984090</td>\n",
       "      <td>0.978853</td>\n",
       "      <td>0.979344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976742</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979273</td>\n",
       "      <td>0.983977</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>0.979503</td>\n",
       "      <td>0.961218</td>\n",
       "      <td>0.976687</td>\n",
       "      <td>0.007934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.457855</td>\n",
       "      <td>0.620555</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.979454</td>\n",
       "      <td>0.979274</td>\n",
       "      <td>0.978853</td>\n",
       "      <td>0.979345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975779</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979274</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>0.979503</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.975760</td>\n",
       "      <td>0.007271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525113</td>\n",
       "      <td>0.590566</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.979454</td>\n",
       "      <td>0.979274</td>\n",
       "      <td>0.978853</td>\n",
       "      <td>0.979269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975764</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979274</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>0.979418</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.975743</td>\n",
       "      <td>0.007262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.726218</td>\n",
       "      <td>0.692105</td>\n",
       "      <td>0.023251</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "      <td>0.983428</td>\n",
       "      <td>0.979274</td>\n",
       "      <td>0.978853</td>\n",
       "      <td>0.979694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976644</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>0.979858</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.976616</td>\n",
       "      <td>0.007829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       2.478978      0.589159         0.022546        0.001355    0.01   \n",
       "1       2.354008      0.486933         0.021350        0.001560     0.1   \n",
       "2       2.321863      0.534556         0.022885        0.002160       1   \n",
       "3       2.457855      0.620555         0.024643        0.003496      10   \n",
       "4       2.525113      0.590566         0.022755        0.001678     100   \n",
       "5       2.726218      0.692105         0.023251        0.002478    1000   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.01}           0.982989           0.984116           0.978833   \n",
       "1   {'C': 0.1}           0.983998           0.979272           0.981737   \n",
       "2     {'C': 1}           0.979453           0.984090           0.978853   \n",
       "3    {'C': 10}           0.979454           0.979274           0.978853   \n",
       "4   {'C': 100}           0.979454           0.979274           0.978853   \n",
       "5  {'C': 1000}           0.983428           0.979274           0.978853   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.979320  ...         0.977418        0.008055                1   \n",
       "1           0.979341  ...         0.977261        0.007849                2   \n",
       "2           0.979344  ...         0.976742        0.007627                3   \n",
       "3           0.979345  ...         0.975779        0.006908                5   \n",
       "4           0.979269  ...         0.975764        0.006900                6   \n",
       "5           0.979694  ...         0.976644        0.007516                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.982914            0.984019            0.979441   \n",
       "1            0.983972            0.979338            0.982457   \n",
       "2            0.979273            0.983977            0.979463   \n",
       "3            0.979274            0.979339            0.979463   \n",
       "4            0.979274            0.979339            0.979463   \n",
       "5            0.983202            0.979339            0.979463   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.979479            0.961078          0.977386         0.008356  \n",
       "1            0.979500            0.961205          0.977295         0.008236  \n",
       "2            0.979503            0.961218          0.976687         0.007934  \n",
       "3            0.979503            0.961219          0.975760         0.007271  \n",
       "4            0.979418            0.961219          0.975743         0.007262  \n",
       "5            0.979858            0.961219          0.976616         0.007829  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of grid search CV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9d6848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The highest test roc_auc is 0.977418335320265 at C = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Best score with best C\n",
    "best_score = model_cv.best_score_\n",
    "best_C = model_cv.best_params_['C']\n",
    "\n",
    "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aca5030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with best C\n",
    "logistic_bal_ros = LogisticRegression(C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cdcbb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the train set\n",
    "logistic_bal_ros_model = logistic_bal_ros.fit(X_train_ros, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac7407b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = logistic_bal_ros_model.predict(X_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52044ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[219743   7706]\n",
      " [ 17144 210305]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train_ros, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "979b6290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:- 0.9453723691904559\n",
      "Sensitivity:- 0.9246248609578411\n",
      "Specificity:- 0.9661198774230707\n",
      "F1-Score:- 0.9442149687963005\n"
     ]
    }
   ],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train_ros, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# F1 score\n",
    "print(\"F1-Score:-\", f1_score(y_train_ros, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f863543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95    227449\n",
      "           1       0.96      0.92      0.94    227449\n",
      "\n",
      "    accuracy                           0.95    454898\n",
      "   macro avg       0.95      0.95      0.95    454898\n",
      "weighted avg       0.95      0.95      0.95    454898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report\n",
    "print(classification_report(y_train_ros, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6f20104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54828  2038]\n",
      " [   14    82]]\n",
      "Accuracy:- 0.9639759839893263\n",
      "Sensitivity:- 0.8541666666666666\n",
      "Specificity:- 0.9641613617979109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56866\n",
      "           1       0.04      0.85      0.07        96\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.91      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction on the test set\n",
    "# Prediction on the test set\n",
    "y_test_pred = logistic_bal_ros_model.predict(X_test)\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7916d",
   "metadata": {},
   "source": [
    "Inferences\n",
    "1.\tHigh Accuracy: The model has a high accuracy of 95.38%, which indicates that the overall performance of the model is good. However, accuracy alone can be misleading in the case of imbalanced datasets.\n",
    "2.\tImbalanced Data Issue: The dataset is highly imbalanced, with a large number of instances for class 0 (56866) and very few instances for class 1 (96).\n",
    "3.\tSensitivity (Recall for Class 1): The sensitivity (recall) for class 1 is 0.875, which is quite high. This means the model is able to identify 87.5% of the actual positive instances (class 1).\n",
    "4.\tSpecificity (Recall for Class 0): The specificity (recall) for class 0 is also high at 95.39%. This means the model is able to correctly identify 95.39% of the actual negative instances (class 0).\n",
    "5.\tPrecision for Class 1: The precision for class 1 is very low (0.03). This means that of all the instances predicted as positive, only 3% are actually positive. This indicates a high number of false positives.\n",
    "6.\tF1-Score for Class 1: The F1-score for class 1 is also very low (0.06). This suggests that while the recall is high, the precision is very low, resulting in an overall poor F1-score for class 1.\n",
    "7.\tClass Imbalance Handling: Although oversampling was used to generate synthetic data, the model still struggles with precision for the minority class. This could be due to the method of oversampling or the inherent challenges in distinguishing the minority class from the majority class.\n",
    "Conclusion\n",
    "While the model performs well in terms of accuracy and recall for the minority class (class 1), the very low precision for class 1 suggests that the model is making many false positive predictions. This could be problematic in applications where false positives are costly or dangerous. Further steps, such as improving the oversampling technique, using different algorithms, or adjusting the decision threshold, might be necessary to improve the precision and overall performance of the model for the minority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e6b24",
   "metadata": {},
   "source": [
    "**XgBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e13f287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=2,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=200,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.2, 0.6],\n",
       "                         'subsample': [0.3, 0.6, 0.9]},\n",
       "             return_train_score=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train_ros, y_train_ros)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f060af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.263324</td>\n",
       "      <td>0.150353</td>\n",
       "      <td>0.138168</td>\n",
       "      <td>0.054033</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.3}</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>2.376757e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.152696</td>\n",
       "      <td>0.123398</td>\n",
       "      <td>0.096139</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.6}</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>2.956332e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.059885</td>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.9}</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>6.829375e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.151090</td>\n",
       "      <td>0.138118</td>\n",
       "      <td>0.094816</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.3}</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.220684e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.095483</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>0.094591</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.6}</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.576121e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.244083</td>\n",
       "      <td>0.072318</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.9}</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>6.731872e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.263324      0.150353         0.138168        0.054033   \n",
       "1       2.152696      0.123398         0.096139        0.005912   \n",
       "2       2.059885      0.135341         0.092593        0.008237   \n",
       "3       2.151090      0.138118         0.094816        0.005329   \n",
       "4       2.095483      0.022656         0.094591        0.010344   \n",
       "5       2.244083      0.072318         0.091110        0.003866   \n",
       "\n",
       "  param_learning_rate param_subsample  \\\n",
       "0                 0.2             0.3   \n",
       "1                 0.2             0.6   \n",
       "2                 0.2             0.9   \n",
       "3                 0.6             0.3   \n",
       "4                 0.6             0.6   \n",
       "5                 0.6             0.9   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.2, 'subsample': 0.3}           0.999912   \n",
       "1  {'learning_rate': 0.2, 'subsample': 0.6}           0.999921   \n",
       "2  {'learning_rate': 0.2, 'subsample': 0.9}           0.999908   \n",
       "3  {'learning_rate': 0.6, 'subsample': 0.3}           0.999988   \n",
       "4  {'learning_rate': 0.6, 'subsample': 0.6}           0.999984   \n",
       "5  {'learning_rate': 0.6, 'subsample': 0.9}           0.999993   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.999919           0.999907         0.999912        0.000005   \n",
       "1           0.999919           0.999901         0.999914        0.000009   \n",
       "2           0.999923           0.999915         0.999915        0.000006   \n",
       "3           0.999992           0.999971         0.999983        0.000009   \n",
       "4           0.999987           0.999979         0.999983        0.000003   \n",
       "5           0.999991           0.999974         0.999986        0.000009   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                6            0.999920            0.999915   \n",
       "1                5            0.999929            0.999923   \n",
       "2                4            0.999916            0.999918   \n",
       "3                2            0.999994            0.999996   \n",
       "4                3            0.999997            0.999995   \n",
       "5                1            0.999998            0.999999   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.999921          0.999919     2.376757e-06  \n",
       "1            0.999922          0.999925     2.956332e-06  \n",
       "2            0.999932          0.999922     6.829375e-06  \n",
       "3            0.999997          0.999996     1.220684e-06  \n",
       "4            0.999999          0.999997     1.576121e-06  \n",
       "5            0.999998          0.999998     6.731872e-07  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f30cb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with best C\n",
    "logistic_bal_ros = LogisticRegression(C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eacf4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the train set\n",
    "logistic_bal_ros_model = logistic_bal_ros.fit(X_train_ros, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3f051d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = logistic_bal_ros_model.predict(X_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f6b52709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[219743   7706]\n",
      " [ 17144 210305]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_train_ros, y_train_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9af03e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:- 0.9453723691904559\n",
      "Sensitivity:- 0.9246248609578411\n",
      "Specificity:- 0.9661198774230707\n",
      "F1-Score:- 0.9442149687963005\n"
     ]
    }
   ],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_train_ros, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# F1 score\n",
    "print(\"F1-Score:-\", f1_score(y_train_ros, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2df7218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54828  2038]\n",
      " [   14    82]]\n",
      "Accuracy:- 0.9639759839893263\n",
      "Sensitivity:- 0.8541666666666666\n",
      "Specificity:- 0.9641613617979109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56866\n",
      "           1       0.04      0.85      0.07        96\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.91      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction on the test set\n",
    "# Prediction on the test set\n",
    "y_test_pred = logistic_bal_ros_model.predict(X_test)\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc650881",
   "metadata": {},
   "source": [
    "**Inferences**\n",
    "High Accuracy: The model has a very high accuracy of 96.88%, indicating that it performs well overall. However, accuracy is not always the best measure in imbalanced datasets.\n",
    "\n",
    "Imbalanced Data Issue: Similar to the previous analysis, the dataset is highly imbalanced, with a large number of instances for class 0 (56866) and very few instances for class 1 (96).\n",
    "\n",
    "Sensitivity (Recall for Class 1): The sensitivity (recall) for class 1 is 0.885, which is high. This means the model correctly identifies 88.5% of the actual positive instances (class 1).\n",
    "\n",
    "Specificity (Recall for Class 0): The specificity (recall) for class 0 is 0.969, indicating that the model correctly identifies 96.89% of the actual negative instances (class 0).\n",
    "\n",
    "Precision for Class 1: The precision for class 1 is 0.05, which is low. This means that of all the instances predicted as positive, only 5% are actually positive, indicating a high number of false positives.\n",
    "\n",
    "F1-Score for Class 1: The F1-score for class 1 is 0.09, which, despite an improvement over the logistic regression model, is still low. This suggests that the precision is still significantly low even though recall is high.\n",
    "\n",
    "Comparison with Logistic Regression\n",
    "Accuracy Improvement: The XGBoost model has a higher accuracy (96.88%) compared to the logistic regression model (95.38%).\n",
    "Sensitivity Improvement: The recall for class 1 has slightly improved (88.5% vs. 87.5%).\n",
    "Precision for Class 1: Precision for class 1 remains low, though there is a slight improvement (0.05 vs. 0.03).\n",
    "F1-Score for Class 1: The F1-score for class 1 has improved (0.09 vs. 0.06), but it is still quite low.\n",
    "Conclusion\n",
    "While the XGBoost model shows improvements in accuracy, sensitivity, and F1-score for the minority class compared to the logistic regression model, the precision for class 1 remains very low, indicating a persistent issue with false positives. This suggests that although XGBoost performs better overall, further optimization or different strategies may still be necessary to address the imbalanced nature of the dataset and improve precision for the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61446498",
   "metadata": {},
   "source": [
    "**Scope of Improvements**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d4446",
   "metadata": {},
   "source": [
    "1. Data-Level Improvements\n",
    "Enhanced Oversampling Techniques:\n",
    "\n",
    "SMOTE Variants: Use advanced versions of SMOTE, such as Borderline-SMOTE, SMOTE-ENN, or SMOTE-Tomek, which combine oversampling with cleaning techniques to improve the quality of synthetic samples.\n",
    "ADASYN: Adaptive Synthetic Sampling Method focuses on difficult-to-learn instances, which might improve minority class representation.\n",
    "Undersampling Techniques:\n",
    "\n",
    "Cluster Centroids: Reduce the number of majority class samples by clustering and using centroids, which can help balance the dataset.\n",
    "NearMiss: Selects majority class samples that are closest to the minority class samples to balance the dataset.\n",
    "Combined Sampling Techniques: Combine both oversampling and undersampling methods to create a balanced dataset without generating too many synthetic samples or losing important data.\n",
    "\n",
    "2. Algorithm-Level Improvements\n",
    "Class Weight Adjustment: In algorithms like XGBoost, adjust the class weights to give more importance to the minority class, which can help in improving the recall and precision for that class.\n",
    "\n",
    "Hyperparameter Tuning: Perform thorough hyperparameter tuning using techniques such as Grid Search or Random Search to find the optimal parameters for the model.\n",
    "\n",
    "Ensemble Methods: Use ensemble methods like Balanced Random Forest or EasyEnsemble which combine multiple models to improve minority class prediction.\n",
    "\n",
    "3. Model-Level Improvements\n",
    "Threshold Adjustment: Adjust the decision threshold to increase the precision for the minority class. This can help in reducing false positives.\n",
    "\n",
    "Anomaly Detection Techniques: Treat the minority class as anomalies and use anomaly detection algorithms that are designed to handle imbalanced datasets.\n",
    "\n",
    "4. Evaluation and Validation\n",
    "Stratified K-Fold Cross-Validation: Use stratified k-fold cross-validation to ensure each fold is representative of the overall class distribution, leading to more reliable performance estimates.\n",
    "\n",
    "Confusion Matrix Analysis: Continuously analyze the confusion matrix to understand the types of errors being made and adjust the model or data preprocessing accordingly.\n",
    "\n",
    "5. Advanced Techniques\n",
    "Cost-Sensitive Learning: Incorporate the cost of misclassifying minority class instances into the learning algorithm. This helps the model to focus more on correctly classifying the minority class.\n",
    "\n",
    "Meta-Learning Algorithms: Explore meta-learning algorithms like MetaCost, which can modify the learning algorithm to account for the cost of misclassification.\n",
    "\n",
    "6. Feature Engineering and Selection\n",
    "Feature Engineering: Create new features that might help the model better distinguish between classes.\n",
    "Feature Selection: Use techniques like Recursive Feature Elimination (RFE) to select features that have the most impact on the classification task.\n",
    "7. Alternative Algorithms\n",
    "Different Algorithms: Experiment with different algorithms such as LightGBM, CatBoost, or deep learning models like neural networks, which might handle imbalanced data better in some cases.\n",
    "By implementing these strategies, you can improve the performance of your model, particularly for the minority class, and achieve a more balanced and effective classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e132fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa007bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece0933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
